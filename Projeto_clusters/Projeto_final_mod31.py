import pandas as pd
import streamlit as st
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.cluster import AgglomerativeClustering
from sklearn import tree
import statsmodels.api as sm
import matplotlib.pyplot as plt


@st.cache_data
def std_df(df):
    var_num = ['Administrative', 'Administrative_Duration', 'Informational',
       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',
       'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay','OperatingSystems', 'Browser', 'Region', 'TrafficType']

    var_cat = ['VisitorType','Weekend', 'Revenue']
    columns_delete = ['ExitRates', 'PageValues','OperatingSystems', 'Browser','TrafficType','Region', 'TrafficType', 'Weekend']
    
    df_pad = pd.DataFrame(StandardScaler().fit_transform(df[var_num]), columns= df[var_num].columns)
    df_pad = (pd.concat([df_pad, pd.get_dummies(df[var_cat],drop_first= True)], axis=1)
              .drop(columns= columns_delete))
    
    return df_pad

@st.cache_data
def print_elbow(df):
    df_pad = std_df(df)
    SSD = []

    for i in range (1, 10):
        km = KMeans(n_clusters= i, n_init=10)
        km = km.fit(df_pad)
        SSD.append(km.inertia_)
         
    db = pd.DataFrame({'num_clusters': list(range(1, len(SSD)+1)), 'SSD': SSD})
    fig, ax = plt.subplots(figsize = (12, 4))
    db.plot(x='num_clusters', y='SSD', ax=ax)
    
    return fig

@st.cache_data
def cluster(df):
    df_pad = std_df(df)
    cluster = AgglomerativeClustering(linkage='complete',
                                  n_clusters=4,
                                  distance_threshold= None).fit(df_pad)
    df_pad['grupo'] = pd.Categorical(cluster.labels_)
    return df_pad

@st.cache_data
def tree(df):
    df_pad = cluster(df)
    # Identificar e converter colunas booleanas
    boolean_columns = df_pad.select_dtypes(include='bool').columns
    df_pad[boolean_columns] = df_pad[boolean_columns].astype(int)

    X = df_pad.drop(columns='grupo')
    y = df_pad['grupo']
    
    model = sm.MNLogit(y, X).fit()
    
    return model

    
# Fun√ß√£o principal da aplica√ß√£o
def main():
    # Configura√ß√£o inicial da p√°gina da aplica√ß√£o
    st.set_page_config(page_title='An√°lise Clusters',
                       layout="wide",
                       initial_sidebar_state='expanded',
                       page_icon= 'https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg',)

    # T√≠tulo principal da aplica√ß√£o
    st.write("""# Clusteriza√ß√£o e an√°lise de grupos üì∂

    Clusterizar um conjunto de dados significa dividir este conjunto em diversos subconjuntos diferentes, de modo
    que essa divis√£o √© feita com base em uma das vari√°veis desse banco de dados. Os conjuntos s√£o criados de tal maneira
    que os indiv√≠duos semelhantes entre si ficam dentro de um mesmo conjunto, e estes conjuntos s√£o diferentes um do outro

    Neste caso iremos analisar uma tabela com diversas informa√ß√µes sobre clientes e se foi feita alguma compra ou n√£o, com isso, 
    iremos agrupar estes clientes em grupos distintos de compradores e an√°lisar como estes grupos s√£o compostos,
    para isso, temos a base de dados abaixo:
    """)
    st.markdown("---")
    
    
    st.write('Segue abaixo uma descri√ß√£o da base de dados e oque cada coluna significa. üìú')
    st.markdown('''|Variavel                |Descri√ß√£o          | 
|------------------------|:-------------------| 
|Administrative          | Quantidade de acessos em p√°ginas administrativas| 
|Administrative_Duration | Tempo de acesso em p√°ginas administrativas | 
|Informational           | Quantidade de acessos em p√°ginas informativas  | 
|Informational_Duration  | Tempo de acesso em p√°ginas informativas  | 
|ProductRelated          | Quantidade de acessos em p√°ginas de produtos | 
|ProductRelated_Duration | Tempo de acesso em p√°ginas de produtos | 
|BounceRates             | *Percentual de visitantes que entram no site e saem sem acionar outros *requests* durante a sess√£o  | 
|ExitRates               | * Soma de vezes que a p√°gina √© visualizada por √∫ltimo em uma sess√£o dividido pelo total de visualiza√ß√µes | 
|PageValues              | * Representa o valor m√©dio de uma p√°gina da Web que um usu√°rio visitou antes de concluir uma transa√ß√£o de com√©rcio eletr√¥nico | 
|SpecialDay              | Indica a proximidade a uma data festiva (dia das m√£es etc) | 
|Month                   | M√™s  | 
|OperatingSystems        | Sistema operacional do visitante | 
|Browser                 | Browser do visitante | 
|Region                  | Regi√£o | 
|TrafficType             | Tipo de tr√°fego                  | 
|VisitorType             | Tipo de visitante: novo ou recorrente | 
|Weekend                 | Indica final de semana | 
|Revenue                 | Indica se houve compra ou n√£o |''')
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìã Dataframe" , "üíª Clusteriza√ß√£o" , "üìä Tratamentos" , "üí° An√°lise Insights", "üèÅ Conclus√µes"])
    st.markdown("---")
    # URL do arquivo
    data_url = 'https://raw.githubusercontent.com/ThiagoVieira96/Projetos-Ebac/main/Projeto_clusters/online_shoppers_intention.csv'

    # Carregar dados diretamente do URL
    df_compras = pd.read_csv(data_url, infer_datetime_format=True)
    
    # Conte√∫do da barra lateral
    st.sidebar.image('https://streamlit.io/images/brand/streamlit-logo-primary-colormark-darktext.png')
    st.sidebar.header("Projeto Cluster üìä")
    st.sidebar.write("""
    Esta aplica√ß√£o realiza clusteriza√ß√£o de clientes pelo perfil de compra, al√©m da an√°lise destes clusters.
    
    - O arquivo de dados utilizado pode ser encontrado [aqui](https://raw.githubusercontent.com/ThiagoVieira96/Projetos-Ebac/main/Projeto_clusters/online_shoppers_intention.csv).
    
    - O reposit√≥rio com o c√≥digo fonte desta aplica√ß√£o pode ser encontrado [aqui](https://github.com/ThiagoVieira96/Projetos-Ebac/tree/main/Projeto_clusters)
    
    Informa√ß√µes adicionais üí°:
    - O gr√°fico do m√©todo do cotovelo foi feito usando clusteriza√ß√£o por KMeans, uma t√©cnica bastante simples e popular em an√°lise de dados.
    - As regress√µes foram feitas usando o m√©todo MNLogit do statsmodels, isso √©, uma regress√£o logistica multivariada.
    """)    
    
    with tab1:
        st.write(''' ## Base de dados üìÇ
                 
        Aqui iremos basicamente visualizar a base de dados sem nenhum tratamento, basicamente para vermos que tipos de dados
     esta base possui, assim como que tipos de tratamentos teremos que realizar 
                 ''')
        
        
        st.write(df_compras.head(10))  
        
        
        col1, col2 = st.columns(2)

# Adicionando caixas de texto nas colunas
        with col1:
            col_1, col_2 = st.columns(2)
            with col_1:
                st.write("Valores Missing",df_compras.isna().sum())
            with col_2:
                st.write("Vari√°veis",df_compras.dtypes)
            

        with col2:
            st.write('An√°lise das vari√°veis:')
            st.write('''\nPela tabela ao lado, vemos que as vari√°veis categoricas s√£o apenas "Month" e "VisitoType",
                     juntamente com "Weekend" e "Revenue" que s√£o booleanas. Al√©m disso, como vimos tamb√©m, n√£o existem colunas faltando neste
                     banco de dados, assim, vamos prosseguir para a padroniza√ß√£o e o tratamento das vari√°veis,
                     em seguida iremos para a divis√£o entre os diferentes tipos de clientes, por fim iremos
                     obter insights a partir de an√°lises estatisticas sobre os grupos.''')
            
    with tab2:
        st.write(''' ## Clusteriza√ß√£o   üíª
                 
                 Agora iremos come√ßar a parte de tratamentos na nossa base de dados, primeiramente vamos separar a base de dados
     nas vari√°veis numericas e n√£o num√©ricas.
     Ap√≥s isso, iremos padronizar as vari√°veis num√©ricas e criar dummies para as categoricas, para isso, iremos assumir o seguinte:
     - O m√™s n√£o interfere na chance de uma pessoa realizar uma compra ou n√£o. Isso nos possibilitar√° remover a vari√°vel "Month",
     o que geraria doze vari√°veis dummy, algo que iria interferir muito na complexidade do modelo, mesmo sabendo que isso
     n√£o √© interiramente verdade.
     Para contornar isso, iremos deixar a coluna "SpecialDay", que mostra a distancia de uma data festiva,
     que tamb√©m interfere na possibilidade de compra.
     Isso ir√° nos poupar de fazer uma an√°lise muito complexa e computacionalmente custosa.''')
        
        st.write('''A primeira parte dos tratamentos ser√° dividir os grupos em clusters diferentes, ou seja, grupo distintos entre si,
                 por√©m os membros de um mesmo grupo s√£o semelhantes. Para isso, o primeiro passo ser√° definir o n√∫mero de grupos a ser divididos,
                 para isso, usamos uma t√©cnica chamada m√©todo do cotovelo, isso √©, quando houver uma queda brusca nos valores de y em rela√ß√£o a x,
                 teremos a quantidade ideal de clusters.''')
        
        st.pyplot(print_elbow(df_compras))
        st.write('''Com base no gr√°fico acima, iremos escolher dividir os clientes em 4 grupos diferentes,
                 este n√∫mero n√£o somente √© um bom n√∫mero, como mostrado pelo gr√°fico,
                 mas tamb√©m n√£o √© um n√∫mero muito grande, a ponto da nossa an√°lise ser afetada.''')
    with tab3:
        st.write('''#### Agora, com os grupos definidos, podemos rodar uma √°rvore de regress√£o para identificar as vari√°veis mais influentes para a nossa vari√°vel resposta. com isso, poderemos identificar o perfil dos nossos clientes. ‚úÖ''')
        tab_sum_1, tab_sum_2 = st.tabs(['An√°lise tr√™s primeiros grupos', 'An√°lise tr√™s √∫ltimos grupos'])
        
        with tab_sum_1:
            st.text(tree(df_compras).summary2())
            
        with tab_sum_2:
            st.text(tree(df_compras).summary())
        
        st.write('''Como vemos acima, cada um dos grupos possui vari√°veis mais importantes para seu resultado e outras menos,
                 iremos aceitar em cada grupo as vari√°veis com o valor de "P > |t|" menor que 0,05. Com isso, as vari√°veis aceitas
                 de cada grupo ser√£o: ''')
        
        st.write('- Grupo 0: Administrative, Informational,  Informational_Duration, ProductRelated, ProductRelated_Duration, BounceRates, SpecialDay, VisitorType_Returning_Visitor.')
        st.write('- Grupo 1: Administrative, Informational,  Informational_Duration, ProductRelated, ProductRelated_Duration, BounceRates, SpecialDay, VisitorType_Returning_Visitor. ')
        st.write('- Grupo 2: Informational_Duration, VisitorType_Returning_Visitor.')
        st.write('- Grupo 4: Administrative_Duration, Informational, ProductRelated, ProductRelated_Duration, BounceRates, VisitorType_Returning_Visitor.')
        st.write('Podemos criar grupamentos entre estes grupos e as vari√°veis mais importantes para eles, assim, poderemos descobrir o perfil de cada grupo.')
        
    with tab4:
        df = pd.concat([df_compras, cluster(df_compras)['grupo']], axis= 1)
        
        st.write("## Estat√≠sticas por Grupo üìë")
        
        # Obter todos os valores √∫nicos da coluna 'grupo'
        grupos = df['grupo'].sort_values().unique()
        
        # Iterar sobre cada grupo e calcular estat√≠sticas descritivas
        for grupo in grupos:
            st.write(f"### Estat√≠sticas para o Grupo {grupo}")
            
            # Filtrar o DataFrame para o grupo atual
            df_grupo = df[df['grupo'] == grupo]
            
            if grupo == 0:
                stats = df_grupo[['Administrative', 'Informational',
                              'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',
                              'BounceRates', 'SpecialDay']].describe()
                st.write('''Como podemos ver, o grupo zero √© um grupo de outliers, contendo apenas 3 membros, que provavelmente seriam agrupados
                         juntamente ao grupo 1, caso o n√∫mero de clusters fosse menor. Ao analisar as vari√°veis mais importantes para estes,
                         vemos que os membros deste grupo se destacam por uma grande quantidade de acessos em p√°ginas administrativas, informativas
                         e p√°ginas de produtos, al√©m de passar muito tempo nestas p√°ginas.''')
            elif grupo == 1:
                stats = df_grupo[['Administrative', 'Informational',
                              'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',
                              'BounceRates', 'SpecialDay']].describe()
                st.write('''O grupo 1, como vemos, √© de longe o grupo mais numeroso de todos, com mais de 12000 membros. Mediante an√°lise de suas
                         vari√°veis mais importantes, vemos que este grupo se destaca pela quantidade relativamente pequena de acessos em
                         p√°ginas administrativas e informativas, al√©m do pouco tempo passado nestas p√°ginas, j√° a quantidade de acessos e de tempo passado
                         nestas p√°ginas √© relativamente maior. Outro ponto de interesse √© que uma quantidade apreci√°vel destes membros acessaram estas
                         p√°ginas relativamente pr√≥ximos de dias festivos, al√©m disso, o Bounce Rate, isto √©, o percentual
                        de clientes que acessaram os sites e sa√≠ram sem acionar quaiquer outros requests √© relativamente alto.''')
            elif grupo == 2:
                stats = df_grupo[['Informational_Duration']].describe()
                st.write('''Sobre o grupo 2, a √∫nica vari√°vel estatisticamente relevante para este grupo √© a vari√°vel "Informational_Duration"
                         , como s√≥ temos essa vari√°vel para a an√°lise, vemos que os membros deste grupo passam uma quantidade de tempo em p√°ginas
                         informativas que √© intermediaria entre os grupos 0 e 1, al√©m disso, existe um grande desvio padr√£o neste grupo, sendo assim,
                         o tempo que estes usu√°rios passam nestas p√°ginas varia bastante.''')
                
            else:
                stats = df_grupo[['Administrative_Duration', 'Informational', 'ProductRelated', 'ProductRelated_Duration',
                              'BounceRates']].describe()
                st.write('''Por fim, o grupo 3 se destaca pela grande quantidade de tempo passado em p√°ginas administrativas e principalmente em
                         p√°ginas relacionadas √† produtos, sendo esta uma das maiores m√©dias em todos os grupos. Al√©m disso, a quantidade de acessos
                         em p√°ginas informacionais e p√°ginas relacionadas √† produtos tamb√©m √© grande, ainda que n√£o t√£o grande quanto o grupo 0, por√©m,
                         como o grupo 0 √© composto apenas por outliers, podemos afirmar que a quantidade de tempo passada pelo grupo 3 nessas p√°ginas
                         √©, em m√©dia, a maior entre os grupo.''')
            st.write(stats)
    with tab5:
        st.write('### Com base nas an√°lises feitas, podemos chegar √†s seguintes conclus√µes:')
        st.write('''
                 - As vari√°veis mais importantes para separar os grupos s√£o o tempo de uso e a quantidade de acessos em sites informativos, administrativos
                 e sites de produtos, isso √© verdade para todos os grupos.
                 - O grupo 0 √© claramente um grupo de outliers do grupo 1, o mais populoso deles, isso somente ocorreu pois o n√∫mero de clusters foi predefinido
                 para 4. Caso fossem feitos 3 clusters os membros do grupo 0 teriam sido agrupados juntamente com o grupo 1.
                 - Justamente por ser t√£o populoso, √© perfeitamente poss√≠vel que existam outros subgrupos dentro do grupo 1, caso sejam feitos mais clusters
                 estes subgrupos poderiam comp√¥r um grupo separado.
                 - O fato do grupo 1 ser t√£o populoso indica que a maior parte dos clientes possui tend√™ncias semelhantes.
                 ''')
        
if __name__ == '__main__':
    main()
