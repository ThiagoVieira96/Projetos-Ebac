{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cabec%CC%A7alho_notebook.png](cabecalho_notebook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de Atividade Humana com PCA\n",
    "\n",
    "Vamos trabalhar com a base da demonstração feita em aula, mas vamos explorar um pouco melhor como é o desempenho da árvore variando o número de componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "filename_features = \"./human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/features.txt\"\n",
    "filename_labels = \"./human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/activity_labels.txt\"\n",
    "\n",
    "filename_subtrain = \"./human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/train/subject_train.txt\"\n",
    "filename_xtrain = \"./human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/train/X_train.txt\"\n",
    "filename_ytrain = \"./human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/train/y_train.txt\"\n",
    "\n",
    "filename_subtest = \"./human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/subject_test.txt\"\n",
    "ffilename_xtest = \"./human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/X_test.txt\"\n",
    "filename_ytest = \"./human+activity+recognition+using+smartphones/UCI HAR Dataset/UCI HAR Dataset/test/y_test.txt\"\n",
    "\n",
    "features = pd.read_csv(filename_features, header=None, names=['nome_var'], sep=\"#\")\n",
    "labels = pd.read_csv(filename_labels, delim_whitespace=True, header=None, names=['cod_label', 'label'])\n",
    "subject_train = pd.read_csv(filename_subtrain, header=None, names=['subject_id'])\n",
    "subject_test = pd.read_csv(filename_subtest, header=None, names=['subject_id'])\n",
    "\n",
    "X_train = pd.read_csv(filename_xtrain, delim_whitespace=True, header=None, names=features['nome_var'].tolist())\n",
    "X_test = pd.read_csv(ffilename_xtest, delim_whitespace=True, header=None, names=features['nome_var'].tolist())\n",
    "\n",
    "y_train = pd.read_csv(filename_ytrain, header=None, names=['cod_label'])\n",
    "y_test = pd.read_csv(filename_ytest, header=None, names=['cod_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA com variáveis padronizadas\n",
    "\n",
    "Reflexão sobre a escala das variáveis:\n",
    "\n",
    "**Variáveis em métricas muito diferentes** podem interferir na análise de componentes principais. Lembra que variância é informação pra nós? Pois bem, tipicamente se há uma variável monetária como salário, vai ter uma ordem de variabilidade bem maior que número de filhos, tempo de emprego ou qualquer variável dummy. Assim, as variáveis de maior variância tendem a \"dominar\" a análise. Nesses casos é comum usar a padronização das variáveis.\n",
    "\n",
    "Faça duas análises de componentes principais para a base do HAR - com e sem padronização e compare:\n",
    "\n",
    "- A variância explicada por componente\n",
    "- A variância explicada acumulada por componente\n",
    "- A variância percentual por componente\n",
    "- A variância percentual acumulada por componente\n",
    "- Quantas componentes você escolheria, em cada caso para explicar 90% da variância?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 198 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 tBodyAcc-mean()-X</th>\n",
       "      <th>2 tBodyAcc-mean()-Y</th>\n",
       "      <th>3 tBodyAcc-mean()-Z</th>\n",
       "      <th>4 tBodyAcc-std()-X</th>\n",
       "      <th>5 tBodyAcc-std()-Y</th>\n",
       "      <th>6 tBodyAcc-std()-Z</th>\n",
       "      <th>7 tBodyAcc-mad()-X</th>\n",
       "      <th>8 tBodyAcc-mad()-Y</th>\n",
       "      <th>9 tBodyAcc-mad()-Z</th>\n",
       "      <th>10 tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>552 fBodyBodyGyroJerkMag-meanFreq()</th>\n",
       "      <th>553 fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>554 fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>555 angle(tBodyAccMean,gravity)</th>\n",
       "      <th>556 angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>557 angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>558 angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>559 angle(X,gravityMean)</th>\n",
       "      <th>560 angle(Y,gravityMean)</th>\n",
       "      <th>561 angle(Z,gravityMean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200628</td>\n",
       "      <td>-0.063678</td>\n",
       "      <td>-0.419600</td>\n",
       "      <td>-0.868755</td>\n",
       "      <td>-0.939377</td>\n",
       "      <td>-0.737479</td>\n",
       "      <td>-0.859758</td>\n",
       "      <td>-0.938955</td>\n",
       "      <td>-0.766385</td>\n",
       "      <td>-0.855978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.795305</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>-0.276380</td>\n",
       "      <td>-0.360579</td>\n",
       "      <td>0.062935</td>\n",
       "      <td>-0.778374</td>\n",
       "      <td>-0.026079</td>\n",
       "      <td>-0.687172</td>\n",
       "      <td>0.407918</td>\n",
       "      <td>-0.007567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055944</td>\n",
       "      <td>0.031484</td>\n",
       "      <td>-0.253891</td>\n",
       "      <td>-0.875366</td>\n",
       "      <td>-0.923839</td>\n",
       "      <td>-0.849247</td>\n",
       "      <td>-0.868472</td>\n",
       "      <td>-0.921936</td>\n",
       "      <td>-0.848870</td>\n",
       "      <td>-0.871300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130605</td>\n",
       "      <td>-0.897296</td>\n",
       "      <td>-0.767938</td>\n",
       "      <td>0.133002</td>\n",
       "      <td>-0.021460</td>\n",
       "      <td>-1.218722</td>\n",
       "      <td>1.484369</td>\n",
       "      <td>-0.694091</td>\n",
       "      <td>0.409089</td>\n",
       "      <td>0.007875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073510</td>\n",
       "      <td>-0.043414</td>\n",
       "      <td>-0.076289</td>\n",
       "      <td>-0.868980</td>\n",
       "      <td>-0.907698</td>\n",
       "      <td>-0.893724</td>\n",
       "      <td>-0.863078</td>\n",
       "      <td>-0.898793</td>\n",
       "      <td>-0.896640</td>\n",
       "      <td>-0.863264</td>\n",
       "      <td>...</td>\n",
       "      <td>1.152257</td>\n",
       "      <td>-0.260860</td>\n",
       "      <td>-0.438286</td>\n",
       "      <td>-0.377815</td>\n",
       "      <td>0.391949</td>\n",
       "      <td>0.151197</td>\n",
       "      <td>1.704085</td>\n",
       "      <td>-0.702191</td>\n",
       "      <td>0.410260</td>\n",
       "      <td>0.026501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066691</td>\n",
       "      <td>-0.208407</td>\n",
       "      <td>-0.249695</td>\n",
       "      <td>-0.870566</td>\n",
       "      <td>-0.939959</td>\n",
       "      <td>-0.921743</td>\n",
       "      <td>-0.864445</td>\n",
       "      <td>-0.938060</td>\n",
       "      <td>-0.925216</td>\n",
       "      <td>-0.863264</td>\n",
       "      <td>...</td>\n",
       "      <td>1.112694</td>\n",
       "      <td>0.591005</td>\n",
       "      <td>0.463123</td>\n",
       "      <td>-0.135016</td>\n",
       "      <td>-0.033635</td>\n",
       "      <td>1.037781</td>\n",
       "      <td>-1.002951</td>\n",
       "      <td>-0.701636</td>\n",
       "      <td>0.414622</td>\n",
       "      <td>0.031712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030467</td>\n",
       "      <td>0.027585</td>\n",
       "      <td>-0.109840</td>\n",
       "      <td>-0.875128</td>\n",
       "      <td>-0.934815</td>\n",
       "      <td>-0.921281</td>\n",
       "      <td>-0.867325</td>\n",
       "      <td>-0.931726</td>\n",
       "      <td>-0.927965</td>\n",
       "      <td>-0.870201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149567</td>\n",
       "      <td>-0.138505</td>\n",
       "      <td>-0.240296</td>\n",
       "      <td>0.340383</td>\n",
       "      <td>0.268468</td>\n",
       "      <td>1.125841</td>\n",
       "      <td>-1.276196</td>\n",
       "      <td>-0.700104</td>\n",
       "      <td>0.425434</td>\n",
       "      <td>0.045222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1 tBodyAcc-mean()-X  2 tBodyAcc-mean()-Y  3 tBodyAcc-mean()-Z  \\\n",
       "0             0.200628            -0.063678            -0.419600   \n",
       "1             0.055944             0.031484            -0.253891   \n",
       "2             0.073510            -0.043414            -0.076289   \n",
       "3             0.066691            -0.208407            -0.249695   \n",
       "4             0.030467             0.027585            -0.109840   \n",
       "\n",
       "   4 tBodyAcc-std()-X  5 tBodyAcc-std()-Y  6 tBodyAcc-std()-Z  \\\n",
       "0           -0.868755           -0.939377           -0.737479   \n",
       "1           -0.875366           -0.923839           -0.849247   \n",
       "2           -0.868980           -0.907698           -0.893724   \n",
       "3           -0.870566           -0.939959           -0.921743   \n",
       "4           -0.875128           -0.934815           -0.921281   \n",
       "\n",
       "   7 tBodyAcc-mad()-X  8 tBodyAcc-mad()-Y  9 tBodyAcc-mad()-Z  \\\n",
       "0           -0.859758           -0.938955           -0.766385   \n",
       "1           -0.868472           -0.921936           -0.848870   \n",
       "2           -0.863078           -0.898793           -0.896640   \n",
       "3           -0.864445           -0.938060           -0.925216   \n",
       "4           -0.867325           -0.931726           -0.927965   \n",
       "\n",
       "   10 tBodyAcc-max()-X  ...  552 fBodyBodyGyroJerkMag-meanFreq()  \\\n",
       "0            -0.855978  ...                            -0.795305   \n",
       "1            -0.871300  ...                             0.130605   \n",
       "2            -0.863264  ...                             1.152257   \n",
       "3            -0.863264  ...                             1.112694   \n",
       "4            -0.870201  ...                            -0.149567   \n",
       "\n",
       "   553 fBodyBodyGyroJerkMag-skewness()  554 fBodyBodyGyroJerkMag-kurtosis()  \\\n",
       "0                             0.025958                            -0.276380   \n",
       "1                            -0.897296                            -0.767938   \n",
       "2                            -0.260860                            -0.438286   \n",
       "3                             0.591005                             0.463123   \n",
       "4                            -0.138505                            -0.240296   \n",
       "\n",
       "   555 angle(tBodyAccMean,gravity)  556 angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "0                        -0.360579                                  0.062935   \n",
       "1                         0.133002                                 -0.021460   \n",
       "2                        -0.377815                                  0.391949   \n",
       "3                        -0.135016                                 -0.033635   \n",
       "4                         0.340383                                  0.268468   \n",
       "\n",
       "   557 angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                             -0.778374   \n",
       "1                             -1.218722   \n",
       "2                              0.151197   \n",
       "3                              1.037781   \n",
       "4                              1.125841   \n",
       "\n",
       "   558 angle(tBodyGyroJerkMean,gravityMean)  559 angle(X,gravityMean)  \\\n",
       "0                                 -0.026079                 -0.687172   \n",
       "1                                  1.484369                 -0.694091   \n",
       "2                                  1.704085                 -0.702191   \n",
       "3                                 -1.002951                 -0.701636   \n",
       "4                                 -1.276196                 -0.700104   \n",
       "\n",
       "   560 angle(Y,gravityMean)  561 angle(Z,gravityMean)  \n",
       "0                  0.407918                 -0.007567  \n",
       "1                  0.409089                  0.007875  \n",
       "2                  0.410260                  0.026501  \n",
       "3                  0.414622                  0.031712  \n",
       "4                  0.425434                  0.045222  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def padroniza(s):\n",
    "    if s.std() > 0:\n",
    "        s = (s - s.mean())/s.std()\n",
    "    return s\n",
    "\n",
    "X_train_pad = pd.DataFrame(X_train).apply(padroniza, axis=0)\n",
    "X_train_pad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pad = pd.DataFrame(X_test).apply(padroniza, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 375 ms\n",
      "Wall time: 446 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Primeiramente iremos fazer o PCA para as variáveis não padronizadas\n",
    "prcomp = PCA().fit(X_train)\n",
    "variance = prcomp.explained_variance_ #Variancia explicada\n",
    "variance_cum = prcomp.explained_variance_.cumsum() #Variancia explicada acumulada\n",
    "variance_pct = prcomp.explained_variance_ratio_# Variancia percentual\n",
    "variance_pct_cum = variance_pct.cumsum() #Variancia percentual acumulada\n",
    "n_components_90 = np.argmax(variance_pct_cum >= 0.9) + 1\n",
    "n_components_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 375 ms\n",
      "Wall time: 470 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Agora, iremos usar as variavéis padronizadas.\n",
    "prcomp_2 = PCA().fit(X_train_pad)\n",
    "variance = prcomp_2.explained_variance_ #Variancia explicada\n",
    "variance_cum = prcomp_2.explained_variance_.cumsum() #Variancia explicada acumulada\n",
    "variance_pct = prcomp_2.explained_variance_ratio_ # Variancia percentual\n",
    "variance_pct_cum = prcomp_2.explained_variance_ratio_.cumsum() #Variancia percentual acumulada\n",
    "n_components_90 = np.argmax(variance_pct_cum >= 0.9) + 1\n",
    "n_components_90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelos exemplos acima, vemos que a quantidade de componentes para explicar 90% da variância é maior quando as variáveis estão padronizadas,<br> isso ocorre pois a padronização muda a escala das variáveis, deixando-as com média zero e desvio padrão igual a um.<br> Com isso, a variância se distribui mais uniformemente entre as variáveis, logo, como visto,<br> pode ser necessário um maior número de variáveis para se explicar a mesma variância,<br> já que essa se encontra menos concentrada nos primeiros componentes da PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore com PCA\n",
    "\n",
    "Faça duas uma árvore de decisão com 10 componentes principais - uma com base em dados padronizados e outra sem padronizar. Utilize o ```ccp_alpha=0.001```.\n",
    "\n",
    "Compare a acurácia na base de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 10).fit(X_train)\n",
    "pca_pad = PCA(n_components= 10).fit(X_train_pad)\n",
    "pc_train = pca.transform(X_train)\n",
    "pc_test = pca.transform(X_test)\n",
    "pc_train_pad = pca_pad.transform(X_train_pad)\n",
    "pc_test_pad = pca_pad.transform(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia da árvore não padronizada: 0.8008143875127248\n",
      "Acurácia da árvore padronizada: 0.7329487614523243\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 368 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = DecisionTreeClassifier(ccp_alpha= 0.01).fit(pc_train, y_train)\n",
    "clf_pad = DecisionTreeClassifier(ccp_alpha= 0.01).fit(pc_train_pad, y_train)\n",
    "predict = clf.predict(pc_test)\n",
    "predict_pad = clf_pad.predict(pc_test_pad)\n",
    "print(f'Acurácia da árvore não padronizada: {accuracy_score(y_test, predict)}')\n",
    "print(f'Acurácia da árvore padronizada: {accuracy_score(y_test, predict_pad)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, como foi explicado, a padronização deixa a variância mais homegeneizada entre as variáveis, isso afeta também a acurácia, pois,<br> como vemos, ela é menor em uma árvore com as variáveis padronizadas, sendo que ambas árvores possuem a mesma quantidade de componentes<br> e o mesmo ccp_alpha."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
